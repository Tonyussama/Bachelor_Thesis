import sys
import cv2
import numpy as np
import time
import imutils
from matplotlib import pyplot as plt

# Function for stereo vision and depth estimation
import triangulation as tri
import calibration

# Mediapipe for face detection
import mediapipe as mp
import time

classNames = []
classFile = 'coco.names'
with open(classFile, 'rt') as f:
    classNames = f.read().rstrip('\n').split('\n')
configPath = 'ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt'
weightsPath = 'frozen_inference_graph.pb'


net = cv2.dnn_DetectionModel(weightsPath, configPath)
net.setInputSize(320, 320)
net.setInputScale(1.0 / 127.5)
net.setInputMean((127.5, 127.5, 127.5))
net.setInputSwapRB(True)


url2 = 'rtsp://admin:Tony2299@192.168.1.110/cam/realmonitor?channel=1&subtype=00&authbasic=YWRtaW46YWRtaW4='

url = 'rtsp://admin:Tony0000@192.168.1.108/cam/realmonitor?channel=1&subtype=00&authbasic=YWRtaW46YWRtaW4='


# Open both cameras
cap_right = cv2.VideoCapture(url)
cap_left = cv2.VideoCapture(url2)


# Stereo vision setup parameters
frame_rate = 120  # Camera frame rate (maximum at 120 fps)
B = 5  # Distance between the cameras [cm]
f = 2.8  # Camera lense's focal length [mm]
alpha = 100  # Camera field of view in the horisontal plane [degrees]


# Main program loop with face detector and depth estimation using stereo vision
while True:

    while (cap_right.isOpened() and cap_left.isOpened()):

        succes_right, frame_right = cap_right.read()
        succes_left, frame_left = cap_left.read()
        frame_right = cv2.flip(frame_right, 0)
        frame_left = cv2.flip(frame_left, 0)
        classIdsL, confsL, bboxL = net.detect(frame_left, confThreshold=0.6)
        classIdsR, confsR, bboxR = net.detect(frame_right, confThreshold=0.6)
        # if classNames[classIds] == "person":
        # print(classIds)
        x = [1]
        count = 1

    ################## CALIBRATION #########################################################

        frame_right, frame_left = calibration.undistortRectify(
            frame_right, frame_left)

    ########################################################################################

        # If cannot catch any frame, break
        
        if len(classIdsL) != 0:
            for classIdL, confidenceL, borderL in zip(classIdsL.flatten(), confsL.flatten(), bboxL):
                if classNames[classIdL - 1] == "person":
                    cv2.rectangle(frame_left, borderL, color=(0, 255, 0), thickness=2)
                    cv2.putText(frame_left, "This is a "+classNames[classIdL - 1].upper(), (borderL[0] + 10, borderL[1] + 30),
                                cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 2)
                # cv2.putText(img, "accuracy ="+str(round(confidence * 100, 2))+"%", (border[0] + 10, border[1] + 60),
                # cv2.FONT_HERSHEY_COMPLEX, 0.8, (0, 255, 255), 2)
                    indexL = np.where(classIdsL != 1)
                    classIdsL = np.delete(classIdsL, indexL)
                    cv2.putText(frame_left, "Counter = " + str(len(classIdsL)), (00, 50),
                                cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 2)
                # print(border)

                    if len(borderL) != 0:
                        xl = (borderL[0])
                        yl = (borderL[1])
                        wl = (borderL[2])
                        hl = (borderL[3])
                        cxl, cyl = int((2*xl + wl) / 2), int((2*yl + hl) / 2)
                        cv2.circle(frame_left, (cxl, cyl), 5, (0, 0, 255), -1)
                       
                        print("person" + str(count))
                        print(cxl, cyl)
                        center_point_left = (((2*xl + wl) / 2),((2*yl + hl) / 2))
                        count = count + 1

        if len(classIdsR) != 0:
            for classIdsR, confidenceR, borderR in zip(classIdsR.flatten(), confsR.flatten(), bboxR):
                if classNames[classIdsR - 1] == "person":
                    cv2.rectangle(frame_right, borderR, color=(0, 255, 0), thickness=2)
                    cv2.putText(frame_right, "This is a "+classNames[classIdsR - 1].upper(), (borderR[0] + 10, borderR[1] + 30),
                                cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 2)
                # cv2.putText(img, "accuracy ="+str(round(confidence * 100, 2))+"%", (border[0] + 10, border[1] + 60),
                # cv2.FONT_HERSHEY_COMPLEX, 0.8, (0, 255, 255), 2)
                    indexR = np.where(classIdsR != 1)
                    classIdsR = np.delete(classIdsR, indexR)
                    cv2.putText(frame_right, "Counter = " + str(len(classIdsR)), (00, 50),
                                cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 2)
                # print(border)

                    if len(borderR) != 0:
                        xr = (borderR[0])
                        yr = (borderR[1])
                        wr = (borderR[2])
                        hr = (borderR[3])
                        cxr, cyr = int((2*xr + wr) / 2), int((2*yr + hr) / 2)
                        cv2.circle(frame_right, (cxr, cyr), 5, (0, 0, 255), -1)
                       
                        print("person" + str(count))
                        print(cxr, cyr)
                        center_point_right = (((2*xr + wr) / 2),((2*yr + hr) / 2))
                        count = count + 1

            ################## CALCULATING DEPTH #########################################################
            
                # Function to calculate depth of object. Outputs vector of all depths in case of several balls.
                # All formulas used to find depth is in video presentaion
                depth = tri.find_depth(
                    center_point_right, center_point_left, frame_right, frame_left, B, f, alpha)

                cv2.putText(frame_right, "Distance: " + str(round(depth, 1)),
                            (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 3)
                cv2.putText(frame_left, "Distance: " + str(round(depth, 1)),
                            (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 3)
                # Multiply computer value with 205.8 to get real-life depth in [cm]. The factor was found manually.
                print("Depth: ", str(round(depth, 1)))

            # Show the frames
            cv2.imshow("frame right", frame_right)
            cv2.imshow("frame left", frame_left)

            # Hit "q" to close the window
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break


# Release and destroy all windows before termination
cap_right.release()
cap_left.release()

cv2.destroyAllWindows()
